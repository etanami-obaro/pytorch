{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99ecc6ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pseudocode\n",
    "# for epoch in range(num_epochs):\n",
    "#     for batch in training_data:\n",
    "#         # 1. Forward pass - make predictions\n",
    "#         predictions = model(batch)\n",
    "        \n",
    "#         # 2. Calculate loss - how wrong are we?\n",
    "#         loss = loss_function(predictions, targets)\n",
    "        \n",
    "#         # 3. Backward pass - calculate gradients\n",
    "#         gradients = compute_gradients(loss)\n",
    "        \n",
    "#         # 4. Update weights - take a step downhill\n",
    "#         for param in model.parameters():\n",
    "#             param -= learning_rate * gradient\n",
    "# ```\n",
    "\n",
    "# **That's it. That's gradient descent.**\n",
    "\n",
    "# ---\n",
    "\n",
    "# ### **The Update Rule**\n",
    "\n",
    "# **Core equation:**\n",
    "# ```\n",
    "# w_new = w_old - α × ∂L/∂w\n",
    "# ```\n",
    "\n",
    "# Where:\n",
    "# - **w** = weight\n",
    "# - **α** (alpha) = learning rate (step size)\n",
    "# - **∂L/∂w** = gradient (slope)\n",
    "\n",
    "# **In plain English:**\n",
    "\"Move each weight in the opposite direction of the gradient, proportional to how much it affects the error\"\n",
    "\n",
    "# ---\n",
    "\n",
    "### **Learning Rate: The Most Important Hyperparameter**\n",
    "\n",
    "# **Learning rate (α)** controls step size:\n",
    "# ```\n",
    "# Too small (α = 0.00001):\n",
    "# - Safe, won't overshoot\n",
    "# - But SLOW - takes forever\n",
    "# - Gets stuck in local minima\n",
    "\n",
    "# Too large (α = 0.1):\n",
    "# - Fast initially\n",
    "# - But OVERSHOOTS minimum\n",
    "# - Loss explodes, model diverges\n",
    "\n",
    "# Just right (α = 0.001):\n",
    "# - Fast enough\n",
    "# - Stable convergence\n",
    "# - Goldilocks zone\n",
    "# ```\n",
    "\n",
    "# **Visual:**\n",
    "# ```\n",
    "# Loss\n",
    "#   |     α too large\n",
    "#   |    /\\  /\\  /\\    (bouncing around)\n",
    "#   |   /  \\/  \\/  \\\n",
    "#   |  \n",
    "#   |     α just right\n",
    "#   |    \\\n",
    "#   |     \\___\n",
    "#   |        \\____    (smooth descent)\n",
    "#   |            \\___\n",
    "#   |\n",
    "#   |     α too small\n",
    "#   |    \\\n",
    "#   |     \\\n",
    "#   |      \\\n",
    "#   |       \\_________  (painfully slow)\n",
    "#   |_________________ Iterations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "45ad9b2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e8c599c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 1.6695, -1.7944, -0.0315], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn(3, requires_grad=True)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "413e957d",
   "metadata": {},
   "outputs": [],
   "source": [
    "y= x+2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5942e71c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([3.6695, 0.2056, 1.9685], grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0a3b20d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([26.9299,  0.0846,  7.7497], grad_fn=<MulBackward0>)\n"
     ]
    }
   ],
   "source": [
    "z = y*y*2\n",
    "print(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8d993ad9",
   "metadata": {},
   "outputs": [],
   "source": [
    "z = z.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "07cd4a78",
   "metadata": {},
   "outputs": [],
   "source": [
    "z.backward() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bca44d40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(11.5881, grad_fn=<MeanBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0d81afa3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([4.8926, 0.2742, 2.6246])\n"
     ]
    }
   ],
   "source": [
    "print(x.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a370cb05",
   "metadata": {},
   "outputs": [],
   "source": [
    "v = torch.tensor([0.1,1.0,0.001], dtype=torch.float32)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
